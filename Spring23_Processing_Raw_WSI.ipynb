{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0acb8eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Luca: We must tile all the WSI before proceeding with either segmentation or WSI-level. This notebook does the preprocessing \n",
    "\n",
    "\n",
    "#Segmentation Pipeline\n",
    "    # Tile\n",
    "    # Give tile name based on coordinate\n",
    "    # Extract polygon annotation\n",
    "    # Generate Masks based on Polygon Annotation\n",
    "    # Find BG using ../saved_models/patched_512_NewAnnotation+preprocess_ResNet18_Feb12.pt (in 224)\n",
    "    # Separate tiles into BG, Inf and Healthy folders\n",
    "    \n",
    "#WSI-level Pipeline\n",
    "    # Tile\n",
    "    # Remove BG tiles using ../saved_models/patched_512_NewAnnotation+preprocess_ResNet18_Feb12.pt (in 224)\n",
    "        # and name them sequentially\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38979adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import os.path\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyvips as Vips\n",
    "from tqdm import tqdm\n",
    "from utils import vips_utils, normalize\n",
    "from torchvision import transforms, utils\n",
    "import time\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image, ImageFile\n",
    "import statistics\n",
    "from typing import Optional, Tuple\n",
    "import pylibczi\n",
    "from pylibczi import CziScene\n",
    "import czifile\n",
    "from czifile import CziFile \n",
    "import xml.etree.ElementTree as ET\n",
    "import argparse\n",
    "import gc \n",
    "import psutil\n",
    "import resource\n",
    "import platform\n",
    "import pickle\n",
    "import xmltodict\n",
    "import time\n",
    "import matplotlib.path as mpath\n",
    "from skimage.draw import polygon\n",
    "import cv2\n",
    "import copy\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from skimage import io, transform\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1475bd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMETERS\n",
    "\n",
    "TILE_SIZE = 512\n",
    "\n",
    "WSI_DIR = '/cache/Inf_May23_dataset/'\n",
    "SAVE_DIR = '/cache/S23_Infarct/patched_'+str(TILE_SIZE)+'/'\n",
    "CZ_DIR = '/cache/S23_Infarct/annotation/'\n",
    "MASK_DIR = '/cache/S23_Infarct/masks/'\n",
    "\n",
    "SEGMENTATION_TILE_DIR = '/cache/S23_Infarct/seg_data_'+str(TILE_SIZE)+'/'\n",
    "WSI_TILE_DIR = '/cache/S23_Infarct/wsi_level_data_'+str(TILE_SIZE)+'/'\n",
    "\n",
    "tile_czi = True\n",
    "tile_svs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dcb2c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found WSI folder... \n",
      "All WSIs in wsi_dir: \n",
      "['NA-5029-16_HE.svs', 'NA-5029-17_HE.svs', 'NA-5029-18_HE.svs', 'NA5004-16_HE.svs', 'NA5004-17_HE.svs', 'NA5004-18_HE.svs', 'NA5007-16_HE.svs', 'NA5007-17_HE.svs', 'NA5007-18_HE.svs', 'NA5009-16_HE.svs', 'NA5009-17_HE.svs', 'NA5009-18_HE.svs', 'NA5031-16_HE.svs', 'NA5031-17_HE.svs', 'NA5031-18_HE.svs', 'NA5041-16_HE.svs', 'NA5041-17_HE.svs', 'NA5041-18_HE.svs', 'NA5045-16_HE.svs', 'NA5045-17_HE.svs', 'NA5045-18_HE.svs', 'NA5051-16_HE.czi', 'NA5051-17_HE.czi', 'NA5051-18_HE.czi', 'NA5057-16_HE.svs', 'NA5057-17_HE.svs', 'NA5057-18_HE.svs', 'NA5063-16_HE.czi', 'NA5063-17_HE.czi', 'NA5063-18_HE.czi', 'NA5077-16_HE.czi', 'NA5077-17_HE.czi', 'NA5077-18_HE.czi', 'NA5085-16_HE.czi', 'NA5085-17_HE.czi', 'NA5085-18_HE.czi', 'NA5089-16_HE.czi', 'NA5089-17_HE.czi', 'NA5089-18_HE.czi', 'NA5090-16_HE.czi', 'NA5090-17_HE.czi', 'NA5090-18_HE.czi', 'NA5091-16_HE.czi', 'NA5091-17_HE.czi', 'NA5091-18_HE.czi', 'NA5093-16_HE.czi', 'NA5093-17_HE.czi', 'NA5093-18_HE.czi', 'NA5095-16_HE.czi', 'NA5095-17_HE.czi', 'NA5095-18_HE.czi', 'NA5098-16_HE.czi', 'NA5098-17_HE.czi', 'NA5098-18_HE.czi', 'NA5114-16_HE.czi', 'NA5114-17_HE.czi', 'NA5114-18_HE.czi', 'NA5116-16_HE.czi', 'NA5116-17_HE.czi', 'NA5116-18_HE.czi', 'NA5137-16_HE.czi', 'NA5137-17_HE.czi', 'NA5137-18_HE.czi', 'NA5146-16_HE.svs', 'NA5146-17_HE.svs', 'NA5146-18_HE.svs', 'NA5161-16_HE.czi', 'NA5161-17_HE.czi', 'NA5161-18_HE.czi']\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(WSI_DIR):\n",
    "    print(\"WSI folder does not exist, script should stop now\")\n",
    "else:\n",
    "    if not os.path.exists(SEGMENTATION_TILE_DIR):\n",
    "        print(\"Tile folder you provided us does not exist, being created now...\")\n",
    "        os.makedirs(SEGMENTATION_TILE_DIR)\n",
    "        \n",
    "    if not os.path.exists(WSI_TILE_DIR):\n",
    "        print(\"Tile folder for WSI-level you provided us does not exist, being created now...\")\n",
    "        os.makedirs(WSI_TILE_DIR)\n",
    "\n",
    "    if not os.path.exists(SAVE_DIR):\n",
    "        print(\"Tile folder you provided us does not exist, being created now...\")\n",
    "        os.makedirs(SAVE_DIR)\n",
    "\n",
    "    if not os.path.exists(CZ_DIR):\n",
    "        print(\"Annotation folder you provided us does not exist, being created now...\")\n",
    "        os.makedirs(CZ_DIR)\n",
    "\n",
    "    if not os.path.exists(MASK_DIR):\n",
    "        print(\"Mask folder you provided us does not exist, being created now...\")\n",
    "        os.makedirs(MASK_DIR)\n",
    "\n",
    "    print(\"Found WSI folder... \")\n",
    "    wsi_slides = os.listdir(WSI_DIR)\n",
    "    imagenames = sorted(wsi_slides)\n",
    "    print(\"All WSIs in wsi_dir: \")\n",
    "    print(imagenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e91adac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting tiling....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/69 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NA-5029-16_HE.svs  ......\n",
      "Pre resize:  34033 x 45816\n",
      "Resizing small case\n",
      "Post resize:  68066 x 91632\n",
      "Loaded Image: /cache/Inf_May23_dataset/NA-5029-16_HE.svs\n",
      "/cache/S23_Infarct/patched_512/NA-5029-16_HE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/69 [01:13<1:22:47, 73.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Tiling:  /cache/Inf_May23_dataset/NA-5029-16_HE.svs\n",
      "processed in  73.0525529384613  seconds\n",
      "____________________________________________\n",
      "Loading NA-5029-17_HE.svs  ......\n",
      "Pre resize:  33509 x 53784\n",
      "Resizing small case\n",
      "Post resize:  67018 x 107568\n",
      "Loaded Image: /cache/Inf_May23_dataset/NA-5029-17_HE.svs\n",
      "/cache/S23_Infarct/patched_512/NA-5029-17_HE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/69 [02:37<1:29:10, 79.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Tiling:  /cache/Inf_May23_dataset/NA-5029-17_HE.svs\n",
      "processed in  84.61224961280823  seconds\n",
      "____________________________________________\n",
      "Loading NA-5029-18_HE.svs  ......\n",
      "Pre resize:  41428 x 47808\n",
      "Resizing small case\n",
      "Post resize:  82856 x 95616\n",
      "Loaded Image: /cache/Inf_May23_dataset/NA-5029-18_HE.svs\n",
      "/cache/S23_Infarct/patched_512/NA-5029-18_HE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3/69 [04:08<1:33:06, 84.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Tiling:  /cache/Inf_May23_dataset/NA-5029-18_HE.svs\n",
      "processed in  90.33986592292786  seconds\n",
      "____________________________________________\n",
      "Loading NA5004-16_HE.svs  ......\n",
      "Pre resize:  32738 x 43824\n",
      "Resizing small case\n",
      "Post resize:  65476 x 87648\n",
      "Loaded Image: /cache/Inf_May23_dataset/NA5004-16_HE.svs\n",
      "/cache/S23_Infarct/patched_512/NA5004-16_HE\n"
     ]
    }
   ],
   "source": [
    "###### SEGMENTATION / WSI-level Pipeline - Tile\n",
    "\n",
    "\n",
    "def grabCZI(path, verbose = False):\n",
    "    img = czifile.imread(path)\n",
    "    if verbose:\n",
    "        print(img.shape)\n",
    "        print(img)\n",
    "    \n",
    "    img = np.array(img, dtype = np.uint8)\n",
    "    \n",
    "    scenes = img.shape[0]\n",
    "    time = img.shape[1]\n",
    "    height = img.shape[2]\n",
    "    width = img.shape[3]\n",
    "    channels = img.shape[4]\n",
    "    \n",
    "    \n",
    "    img = img.reshape((height, width, channels))\n",
    "    if verbose:\n",
    "        print(img)\n",
    "        print(img.shape) \n",
    "        \n",
    "    dtype_to_format = {\n",
    "        'uint8': 'uchar',\n",
    "        'int8': 'char',\n",
    "        'uint16': 'ushort',\n",
    "        'int16': 'short',\n",
    "        'uint32': 'uint',\n",
    "        'int32': 'int',\n",
    "        'float32': 'float',\n",
    "        'float64': 'double',\n",
    "        'complex64': 'complex',\n",
    "        'complex128': 'dpcomplex',\n",
    "    }\n",
    "    \n",
    "    ###codes from numpy2vips\n",
    "    height, width, bands = img.shape\n",
    "    img = img.reshape(width * height * bands)\n",
    "    vips = Vips.Image.new_from_memory(img.data, width, height, bands,\n",
    "                                      dtype_to_format['uint8'])\n",
    "    try: \n",
    "        del img, height, width, bands\n",
    "        gc.collect()\n",
    "    except: \n",
    "        pass\n",
    "    \n",
    "    return vips\n",
    "\n",
    "print(\"Starting tiling....\")\n",
    "for imagename in tqdm(imagenames[:]):\n",
    "    start = time.time()\n",
    "    if imagename.split('.')[-1] == 'svs':\n",
    "        NAID = imagename.split('.')[0]\n",
    "        print(\"Loading\", imagename, \" ......\")\n",
    "        vips_img = Vips.Image.new_from_file(WSI_DIR + imagename, level=0)\n",
    "        \n",
    "        print(\"Pre resize: \", vips_img.height, \"x\", vips_img.width)\n",
    "        \n",
    "        if NAID in ['NA5009-16_HE', 'NA5009-17_HE', 'NA5009-18_HE']:\n",
    "            pass\n",
    "            #vips_img = vips_img.resize(0.25)\n",
    "        else:\n",
    "            print(\"Resizing small case\")\n",
    "            vips_img = vips_img.resize(2)\n",
    "            \n",
    "        print(\"Post resize: \", vips_img.height, \"x\", vips_img.width)\n",
    "            \n",
    "        print(\"Loaded Image: \" + WSI_DIR + imagename)\n",
    "\n",
    "        if tile_svs:\n",
    "        \n",
    "            vips_utils.save_and_tile(vips_img, os.path.splitext(imagename)[0] \\\n",
    "                                     , SAVE_DIR, tile_size = TILE_SIZE)\n",
    "            print(\"Done Tiling: \", WSI_DIR + imagename)\n",
    "        \n",
    "    elif imagename.split('.')[-1] == 'czi':\n",
    "        NAID = imagename.split('.')[0]\n",
    "        print(\"Loading\", imagename, \" ......\")\n",
    "        try: \n",
    "            vips_img = grabCZI(WSI_DIR + imagename)\n",
    "            print(\"Loaded Image: \" + WSI_DIR + imagename)\n",
    "            \n",
    "            print(\"Pre resize: \", vips_img.height, \"x\", vips_img.width)\n",
    "            \n",
    "            if tile_czi:\n",
    "        \n",
    "                vips_utils.save_and_tile(vips_img, os.path.splitext(imagename)[0] \\\n",
    "                                         , SAVE_DIR, tile_size = TILE_SIZE)\n",
    "\n",
    "                print(\"Done Tiling: \", WSI_DIR + imagename)\n",
    "                del vips_img\n",
    "                gc.collect()\n",
    "                print(\"Finish Delete\", WSI_DIR + imagename)\n",
    "        except:\n",
    "            print(\"Error in tiling\")\n",
    "        \n",
    "        \n",
    "\n",
    "    else:\n",
    "        print(\"Skipped,\", imagename, '. This file is either not .czi or .svs, or not the file assigned')\n",
    "    \n",
    "    try: \n",
    "        del vips_img \n",
    "        gc.collect()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print(\"processed in \", time.time()-start,\" seconds\")\n",
    "    print(\"____________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732fbf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### WSI-level Pipeline - Find BG using ./patched_512_NewAnnotation+preprocess_ResNet18_Feb12.pt (in 224) and name\n",
    "# files sequentially\n",
    "\n",
    "MODEL_SEG_DIR = './patched_512_NewAnnotation+preprocess_ResNet18_Feb12.pt'\n",
    "\n",
    "seg_model = torchvision.models.resnet18(pretrained=True)\n",
    "seg_model.fc = nn.Linear(512, 3)\n",
    "\n",
    "checkpoint = torch.load(MODEL_SEG_DIR,map_location='cpu')\n",
    "seg_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "seg_model.to(device)\n",
    "\n",
    "\n",
    "for NAID in os.listdir(SAVE_DIR):\n",
    "    start = time.time()\n",
    "    print(\"Processing \", NAID)\n",
    "    if not os.path.exists(WSI_TILE_DIR+NAID):\n",
    "        os.makedirs(WSI_TILE_DIR+NAID)\n",
    "    \n",
    "    seq_ct = 0\n",
    "    for tile_folder in os.listdir(SAVE_DIR+NAID+'/0/'):\n",
    "        for tile in os.listdir(SAVE_DIR+NAID+'/0/'+tile_folder):\n",
    "            \n",
    "            seg_model.train(False)\n",
    "            \n",
    "            img = Image.open(SAVE_DIR+NAID+'/0/'+tile_folder+'/'+tile)\n",
    "            \n",
    "            img_tensor = transforms.ToTensor()(img)\n",
    "            img_tensor = transforms.Normalize(mean=[0.4409763317567454, 0.4016568471536302, 0.4988298669112181],\n",
    "                             std=[0.31297803931100737, 0.2990562933047881, 0.33747493782548915])(img_tensor)\n",
    "            img_tensor = torch.reshape(img_tensor,(1,3,512,512))\n",
    "            img_tensor = img_tensor.cuda()\n",
    "            \n",
    "            predict = seg_model(img_tensor)\n",
    "            preds = F.sigmoid(predict)\n",
    "            _, indices = torch.max(predict.data, 1) # indices = 0:Background, 1:WM, 2:GM\n",
    "            indices = indices.type(torch.uint8)\n",
    "            running_seg =  indices.data.cpu()\n",
    "            \n",
    "            \n",
    "            if running_seg == 0:\n",
    "                shutil.copyfile(SAVE_DIR+NAID+'/0/'+tile_folder+'/'+tile, WSI_TILE_DIR+NAID+'/'+str(seq_ct)+'.jpg')\n",
    "            else:\n",
    "                pass\n",
    "                #print(\"bg removed\")\n",
    "                \n",
    "            seq_ct += 1\n",
    "    print(\"processed in \", time.time()-start,\" seconds\")\n",
    "    print(\"____________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a35334",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### SEGMENTATION - Give tile name based on coordinate\n",
    "\n",
    "print(\"About to change names to add coordinates\")\n",
    "for case_folder in sorted(os.listdir(SAVE_DIR)):\n",
    "    NAID = case_folder\n",
    "    print('NAID: ', NAID)\n",
    "    for tile_folder in sorted(os.listdir(SAVE_DIR+NAID+'/0/')):\n",
    "        # folder_level == y axis distance determinant\n",
    "        # file_level == x axis distance determinant\n",
    "        y0 = int(tile_folder)*TILE_SIZE\n",
    "        y1 = (int(tile_folder)+1)*TILE_SIZE\n",
    "        #print(\"Y axis = (\", y0,',',y1,')')\n",
    "        for tile_file in sorted(os.listdir(SAVE_DIR+NAID+'/0/'+tile_folder+'/')):\n",
    "            x0 = int(tile_file.split('.')[0])*TILE_SIZE\n",
    "            x1 = (int(tile_file.split('.')[0])+1)*TILE_SIZE\n",
    "            #print(\"X axis = (\", x0,',',x1,')')\n",
    "            #print(\"Renaming \", SAVE_DIR+NAID+'/0/'+str(tile_folder)+'/'+tile_file)\n",
    "            os.rename(SAVE_DIR+NAID+'/0/'+str(tile_folder)+'/'+tile_file, \n",
    "                      SAVE_DIR+NAID+'/0/'+str(tile_folder)+'/'+str(y0)+'_'+str(x0)+'_'+str(y1)+'_'+str(x1)+'_'+tile_file)\n",
    "            #print(\"Renamed into \", SAVE_DIR+NAID+'/0/'+tile_folder+'/'+str(y0)+'_'+str(x0)+'_'+str(y1)+'_'+str(x1)+'_'+tile_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e0653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### SEGMENTATION - Extract polygon annotation\n",
    "\n",
    "for imagename in tqdm(imagenames[:]):\n",
    "    start = time.time()\n",
    "    os.makedirs(CZ_DIR+NAID)\n",
    "    if imagename.split('.')[-1] == 'svs':\n",
    "        pass\n",
    "        \n",
    "    elif imagename.split('.')[-1] == 'czi':\n",
    "        NAID = imagename.split('.')[0]\n",
    "        print(\"Loading\", imagename, \" ......\")\n",
    "        try: \n",
    "            czifile = pylibczi.CziFile(WSI_DIR + imagename, metafile_out = CZ_DIR + NAID + '.cz',use_pylibczi=True, verbose=True)\n",
    "            czifile.read_meta()\n",
    "            \n",
    "            tree = ET.parse(CZ_DIR + NAID + '.cz') \n",
    "            root = tree.getroot() \n",
    "            \n",
    "            tree.write(CZ_DIR + NAID + '.xml')\n",
    "        except:\n",
    "            print(\"Error in extracting annotation\")\n",
    "            \n",
    "    print(\"processed in \", time.time()-start,\" seconds\")\n",
    "    print(\"____________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781f3850",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### SEGMENTATION - Generate Masks based on Polygon Annotation\n",
    "\n",
    "def create_polygon_mask(vertex_coordinates, file_dimensions):\n",
    "    \n",
    "    mask = np.zeros(file_dimensions,'uint8')\n",
    "    rr, cc = polygon(vertex_coordinates[:,0],vertex_coordinates[:,1],mask.shape)\n",
    "    mask[rr,cc] = 1\n",
    "    \n",
    "    return mask\n",
    "\n",
    "for imagename in tqdm(imagenames[:]):\n",
    "    start = time.time()\n",
    "    if imagename.split('.')[-1] == 'svs':\n",
    "        pass\n",
    "# TODO: FIND HOW TO REMOVE ANNOTATIONS FROM SVS XML\n",
    "\n",
    "#         NAID = imagename.split('.')[0]\n",
    "#         print(\"Loading\", imagename, \" ......\")\n",
    "#         vips_img = Vips.Image.new_from_file(WSI_DIR + imagename, level=0)\n",
    "        \n",
    "#         dimension_dict[NAID] = [vips_img.height, vips_img.width]\n",
    "        \n",
    "#         print(\"Loaded Image: \" + WSI_DIR + imagename)\n",
    "\n",
    "        \n",
    "    elif imagename.split('.')[-1] == 'czi':\n",
    "        NAID = imagename.split('.')[0]\n",
    "        print(\"Loading\", imagename, \" ......\")\n",
    "        try: \n",
    "            vips_img = grabCZI(WSI_DIR + imagename)\n",
    "            print(\"Loaded Image: \" + WSI_DIR + imagename)\n",
    "            \n",
    "            dimension = [vips_img.height, vips_img.width]\n",
    "            \n",
    "            doc = xmltodict.parse(open(CZ_DIR + NAID + '.xml', 'r', encoding='utf-8').read())\n",
    "            \n",
    "            coords = []\n",
    "            for xy in doc['GraphicsDocument']['Elements']['Bezier'][0]['Geometry']['Points'].split(' '):\n",
    "                coord = [int(float(xy[1])),int(float(xy[0]))]\n",
    "                \n",
    "                ### LUCA NOTE:\n",
    "                    # I just assumed y was [1] and x was [0], this must be checked\n",
    "                \n",
    "                coords.append(coord)\n",
    "                \n",
    "            coords = np.asarray(coords,dtype=np.uint8)\n",
    "            \n",
    "            mask = create_polygon_mask(coords, dimension)\n",
    "            \n",
    "            mask = np.packbits(mask,axis=None)\n",
    "            print(\"Binarized mask\")\n",
    "\n",
    "            np.save(MASK_DIR+NAID+'.npy',mask) \n",
    "            \n",
    "            print(\"processed in \", time.time()-start,\" seconds\")\n",
    "            print(\"____________________________________________\")\n",
    "\n",
    "        except:\n",
    "            print(\"Error in generating masks from polygon\")\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        print(\"Skipped,\", imagename, '. This file is either not .czi or .svs, or not the file assigned')\n",
    "        \n",
    "    del vips_img,coords,mask\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d505eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### SEGMENTATION - Find BG using ../saved_models/patched_512_NewAnnotation+preprocess_ResNet18_Feb12.pt (in 224)\n",
    "\n",
    "MODEL_SEG_DIR = './patched_512_NewAnnotation+preprocess_ResNet18_Feb12.pt'\n",
    "\n",
    "seg_model = torchvision.models.resnet18()\n",
    "seg_model.fc = nn.Linear(512, 3)\n",
    "\n",
    "checkpoint = torch.load(MODEL_SEG_DIR)\n",
    "seg_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "seg_model.to(device)\n",
    "\n",
    "\n",
    "for NAID in os.listdir(SAVE_DIR):\n",
    "    os.makedirs(SEGMENTATION_TILE_DIR+NAID+'/BG/')\n",
    "    for tile_folder in os.listdir(SAVE_DIR+NAID+'/0/'):\n",
    "        for tile in os.listdir(SAVE_DIR+NAID+'/0/'+tile_folder):\n",
    "            seg_model.train(False)\n",
    "            \n",
    "            img = Image.open(SAVE_DIR+NAID+'/0/'+tile_folder+'/'+tile)\n",
    "            \n",
    "            img_tensor = transforms.ToTensor()(img)\n",
    "            img_tensor = transforms.Normalize(mean=[0.4409763317567454, 0.4016568471536302, 0.4988298669112181],\n",
    "                             std=[0.31297803931100737, 0.2990562933047881, 0.33747493782548915])(img_tensor)\n",
    "            img_tensor = torch.reshape(img_tensor,(1,3,512,512))\n",
    "            img_tensor = img_tensor.cuda()\n",
    "            \n",
    "            predict = seg_model(img_tensor)\n",
    "            preds = F.sigmoid(predict)\n",
    "            _, indices = torch.max(predict.data, 1) # indices = 0:Background, 1:WM, 2:GM\n",
    "            indices = indices.type(torch.uint8)\n",
    "            running_seg =  indices.data.cpu()\n",
    "            \n",
    "            \n",
    "            if running_seg == 0:\n",
    "                shutil.copyfile(SAVE_DIR+NAID+'/0/'+tile_folder+'/'+tile, SEGMENTATION_TILE_DIR+NAID+'/BG/'+tile)\n",
    "            else:\n",
    "                pass\n",
    "                #print(\"bg removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e110a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### SEGMENTATION - Separate tiles into BG, Inf and Healthy folders\n",
    "\n",
    "for NAID in os.listdir(SAVE_DIR):\n",
    "    proceed = True\n",
    "    \n",
    "    if os.path.isfile(WSI_DIR+NAID+'.svs'):\n",
    "        vips_img = Vips.Image.new_from_file(WSI_DIR+NAID+'.svs', level=0)\n",
    "    elif os.path.isfile(WSI_DIR+NAID+'.czi'):\n",
    "        vips_img = grabCZI(WSI_DIR+NAID+'.czi')\n",
    "    else:\n",
    "        print(\"Could not find WSI - it is not czi nor svs\")\n",
    "        proceed = False\n",
    "    \n",
    "    if proceed:\n",
    "        os.makedirs(SEGMENTATION_TILE_DIR+NAID+'/Heal/')\n",
    "        os.makedirs(SEGMENTATION_TILE_DIR+NAID+'/Inf/')\n",
    "        \n",
    "        img_dim = [vips_img.height,vips_img.width]\n",
    "        mask = np.load(MASK_DIR+NAID+'.npy')\n",
    "        print(\"Loaded mask at \", MASK_DIR+NAID+'.npy' ,\", about to process...\")\n",
    "\n",
    "        im_size = img_dim[0]*img_dim[1]\n",
    "\n",
    "        mask = np.unpackbits(mask,count=im_size).reshape(img_dim).view(bool)\n",
    "        mask = mask.view(np.uint8)\n",
    "        print(\"Unbinarized mask\")\n",
    "        \n",
    "        \n",
    "        for tile_folder in os.listdir(SAVE_DIR+NAID+'/0/'):\n",
    "            for tile in os.listdir(SAVE_DIR+NAID+'/0/'+tile_folder):\n",
    "\n",
    "                #file naming convention --> y0 x0 y1 x1\n",
    "                y0 = tile.split('_')[0]\n",
    "                x0 = tile.split('_')[1]\n",
    "                y1 = tile.split('_')[2]\n",
    "                x1 = tile.split('_')[3]\n",
    "                \n",
    "                if sum(sum(masky[y0:y1,x0:x1])) >= (512/3):\n",
    "                    shutil.copyfile(SAVE_DIR+NAID+'/0/'+tile_folder+'/'+tile, SEGMENTATION_TILE_DIR+NAID+'/Inf/'+tile)\n",
    "                else:\n",
    "                    shutil.copyfile(SAVE_DIR+NAID+'/0/'+tile_folder+'/'+tile, SEGMENTATION_TILE_DIR+NAID+'/Heal/'+tile)\n",
    "            \n",
    "            \n",
    "    del vips_img, mask\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e93c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877c3f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30ac832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439b5561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce7eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6c4ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532b3d65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8210e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
