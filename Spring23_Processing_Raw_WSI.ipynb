{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87a990ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Luca: We must tile all the WSI before proceeding with either segmentation or WSI-level. This notebook does the preprocessing \n",
    "\n",
    "\n",
    "#Segmentation Pipeline\n",
    "    # Tile\n",
    "    # Give tile name based on coordinate\n",
    "    # Extract polygon annotation\n",
    "    # Generate Masks based on Polygon Annotation\n",
    "    # Find BG using ../saved_models/patched_512_NewAnnotation+preprocess_ResNet18_Feb12.pt (in 224)\n",
    "    # Separate tiles into BG, Inf and Healthy folders\n",
    "#WSI-level Pipeline\n",
    "    # Tile\n",
    "    # Remove BG tiles using ../saved_models/patched_512_NewAnnotation+preprocess_ResNet18_Feb12.pt (in 224)\n",
    "        # and name them sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "529cc090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import os.path\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyvips as Vips\n",
    "from tqdm import tqdm\n",
    "from utils import vips_utils, normalize\n",
    "from torchvision import transforms, utils\n",
    "import time\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image, ImageFile\n",
    "import statistics\n",
    "from typing import Optional, Tuple\n",
    "import pylibczi\n",
    "from pylibczi import CziScene\n",
    "import czifile\n",
    "from czifile import CziFile \n",
    "import xml.etree.ElementTree as ET\n",
    "import argparse\n",
    "import gc \n",
    "import psutil\n",
    "import resource\n",
    "import platform\n",
    "import pickle\n",
    "import xmltodict\n",
    "import time\n",
    "import matplotlib.path as mpath\n",
    "from skimage.draw import polygon\n",
    "import cv2\n",
    "import copy\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from skimage import io, transform\n",
    "### PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25e94be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TILE_SIZE = 512\n",
    "\n",
    "WSI_DIR = '/cache/Inf_May23_dataset/'\n",
    "SAVE_DIR = '/cache/S23_Infarct/patched_'+str(TILE_SIZE)+'/'\n",
    "CZ_DIR = '/cache/S23_Infarct/annotation/'\n",
    "MASK_DIR = '/cache/S23_Infarct/masks/'\n",
    "\n",
    "SEGMENTATION_TILE_DIR = '/cache/S23_Infarct/seg_data_'+str(TILE_SIZE)+'/'\n",
    "WSI_TILE_DIR = '/cache/S23_Infarct/wsi_level_data_'+str(TILE_SIZE)+'/'\n",
    "\n",
    "tile_czi = True\n",
    "tile_svs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "099e84bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found WSI folder... \n",
      "All WSIs in wsi_dir: \n",
      "['NA-5029-16_HE.svs', 'NA-5029-17_HE.svs', 'NA-5029-18_HE.svs', 'NA5004-16_HE.svs', 'NA5004-17_HE.svs', 'NA5004-18_HE.svs', 'NA5007-16_HE.svs', 'NA5007-17_HE.svs', 'NA5007-18_HE.svs', 'NA5009-16_HE.svs', 'NA5009-17_HE.svs', 'NA5009-18_HE.svs', 'NA5031-16_HE.svs', 'NA5031-17_HE.svs', 'NA5031-18_HE.svs', 'NA5041-16_HE.svs', 'NA5041-17_HE.svs', 'NA5041-18_HE.svs', 'NA5045-16_HE.svs', 'NA5045-17_HE.svs', 'NA5045-18_HE.svs', 'NA5051-16_HE.czi', 'NA5051-17_HE.czi', 'NA5051-18_HE.czi', 'NA5057-16_HE.svs', 'NA5057-17_HE.svs', 'NA5057-18_HE.svs', 'NA5063-16_HE.czi', 'NA5063-17_HE.czi', 'NA5063-18_HE.czi', 'NA5077-16_HE.czi', 'NA5077-17_HE.czi', 'NA5077-18_HE.czi', 'NA5085-16_HE.czi', 'NA5085-17_HE.czi', 'NA5085-18_HE.czi', 'NA5089-16_HE.czi', 'NA5089-17_HE.czi', 'NA5089-18_HE.czi', 'NA5090-16_HE.czi', 'NA5090-17_HE.czi', 'NA5090-18_HE.czi', 'NA5091-16_HE.czi', 'NA5091-17_HE.czi', 'NA5091-18_HE.czi', 'NA5093-16_HE.czi', 'NA5093-17_HE.czi', 'NA5093-18_HE.czi', 'NA5095-16_HE.czi', 'NA5095-17_HE.czi', 'NA5095-18_HE.czi', 'NA5098-16_HE.czi', 'NA5098-17_HE.czi', 'NA5098-18_HE.czi', 'NA5114-16_HE.czi', 'NA5114-17_HE.czi', 'NA5114-18_HE.czi', 'NA5116-16_HE.czi', 'NA5116-17_HE.czi', 'NA5116-18_HE.czi', 'NA5137-16_HE.czi', 'NA5137-17_HE.czi', 'NA5137-18_HE.czi', 'NA5146-16_HE.svs', 'NA5146-17_HE.svs', 'NA5146-18_HE.svs', 'NA5161-16_HE.czi', 'NA5161-17_HE.czi', 'NA5161-18_HE.czi']\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(WSI_DIR):\n",
    "    print(\"WSI folder does not exist, script should stop now\")\n",
    "else:\n",
    "    if not os.path.exists(SEGMENTATION_TILE_DIR):\n",
    "        print(\"Tile folder you provided us does not exist, being created now...\")\n",
    "        os.makedirs(SEGMENTATION_TILE_DIR)\n",
    "        \n",
    "    if not os.path.exists(WSI_TILE_DIR):\n",
    "        print(\"Tile folder for WSI-level you provided us does not exist, being created now...\")\n",
    "        os.makedirs(WSI_TILE_DIR)\n",
    "\n",
    "    if not os.path.exists(SAVE_DIR):\n",
    "        print(\"Tile folder you provided us does not exist, being created now...\")\n",
    "        os.makedirs(SAVE_DIR)\n",
    "\n",
    "    if not os.path.exists(CZ_DIR):\n",
    "        print(\"Annotation folder you provided us does not exist, being created now...\")\n",
    "        os.makedirs(CZ_DIR)\n",
    "\n",
    "    if not os.path.exists(MASK_DIR):\n",
    "        print(\"Mask folder you provided us does not exist, being created now...\")\n",
    "        os.makedirs(MASK_DIR)\n",
    "\n",
    "    print(\"Found WSI folder... \")\n",
    "    wsi_slides = os.listdir(WSI_DIR)\n",
    "    imagenames = sorted(wsi_slides)\n",
    "    print(\"All WSIs in wsi_dir: \")\n",
    "    print(imagenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6772d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grabCZI(path, verbose = False):\n",
    "    img = czifile.imread(path)\n",
    "    if verbose:\n",
    "        print(img.shape)\n",
    "        print(img)\n",
    "    \n",
    "    img = np.array(img, dtype = np.uint8)\n",
    "    \n",
    "    scenes = img.shape[0]\n",
    "    time = img.shape[1]\n",
    "    height = img.shape[2]\n",
    "    width = img.shape[3]\n",
    "    channels = img.shape[4]\n",
    "    \n",
    "    \n",
    "    img = img.reshape((height, width, channels))\n",
    "    if verbose:\n",
    "        print(img)\n",
    "        print(img.shape) \n",
    "        \n",
    "    dtype_to_format = {\n",
    "        'uint8': 'uchar',\n",
    "        'int8': 'char',\n",
    "        'uint16': 'ushort',\n",
    "        'int16': 'short',\n",
    "        'uint32': 'uint',\n",
    "        'int32': 'int',\n",
    "        'float32': 'float',\n",
    "        'float64': 'double',\n",
    "        'complex64': 'complex',\n",
    "        'complex128': 'dpcomplex',\n",
    "    }\n",
    "    \n",
    "    ###codes from numpy2vips\n",
    "    height, width, bands = img.shape\n",
    "    img = img.reshape(width * height * bands)\n",
    "    vips = Vips.Image.new_from_memory(img.data, width, height, bands,\n",
    "                                      dtype_to_format['uint8'])\n",
    "    try: \n",
    "        del img, height, width, bands\n",
    "        gc.collect()\n",
    "    except: \n",
    "        pass\n",
    "    \n",
    "    return vips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f781e3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting tiling....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/69 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NA-5029-16_HE.svs  ......\n",
      "Pre resize:  34033 x 45816\n",
      "Resizing small case\n",
      "Post resize:  68066 x 91632\n",
      "Loaded Image: /cache/Inf_May23_dataset/NA-5029-16_HE.svs\n",
      "/cache/S23_Infarct/patched_512/NA-5029-16_HE\n"
     ]
    }
   ],
   "source": [
    "###### SEGMENTATION / WSI-level Pipeline - Tile\n",
    "\n",
    "print(\"Starting tiling....\")\n",
    "for imagename in tqdm(imagenames[:]):\n",
    "    start = time.time()\n",
    "    if imagename.split('.')[-1] == 'svs':\n",
    "        NAID = imagename.split('.')[0]\n",
    "        print(\"Loading\", imagename, \" ......\")\n",
    "        vips_img = Vips.Image.new_from_file(WSI_DIR + imagename, level=0)\n",
    "        \n",
    "        print(\"Pre resize: \", vips_img.height, \"x\", vips_img.width)\n",
    "        \n",
    "        if NAID in ['NA5009-16_HE', 'NA5009-17_HE', 'NA5009-18_HE']:\n",
    "            pass\n",
    "            #vips_img = vips_img.resize(0.25)\n",
    "        else:\n",
    "            print(\"Resizing small case\")\n",
    "            vips_img = vips_img.resize(2)\n",
    "            \n",
    "        print(\"Post resize: \", vips_img.height, \"x\", vips_img.width)\n",
    "            \n",
    "        print(\"Loaded Image: \" + WSI_DIR + imagename)\n",
    "\n",
    "        if tile_svs:\n",
    "        \n",
    "            vips_utils.save_and_tile(vips_img, os.path.splitext(imagename)[0] \\\n",
    "                                     , SAVE_DIR, tile_size = TILE_SIZE)\n",
    "            print(\"Done Tiling: \", WSI_DIR + imagename)\n",
    "        \n",
    "    elif imagename.split('.')[-1] == 'czi':\n",
    "        NAID = imagename.split('.')[0]\n",
    "        print(\"Loading\", imagename, \" ......\")\n",
    "        try: \n",
    "            vips_img = grabCZI(WSI_DIR + imagename)\n",
    "            print(\"Loaded Image: \" + WSI_DIR + imagename)\n",
    "            \n",
    "            print(\"Pre resize: \", vips_img.height, \"x\", vips_img.width)\n",
    "            \n",
    "            if tile_czi:\n",
    "        \n",
    "                vips_utils.save_and_tile(vips_img, os.path.splitext(imagename)[0] \\\n",
    "                                         , SAVE_DIR, tile_size = TILE_SIZE)\n",
    "\n",
    "                print(\"Done Tiling: \", WSI_DIR + imagename)\n",
    "                del vips_img\n",
    "                gc.collect()\n",
    "                print(\"Finish Delete\", WSI_DIR + imagename)\n",
    "        except:\n",
    "            print(\"Error in tiling\")\n",
    "        \n",
    "        \n",
    "\n",
    "    else:\n",
    "        print(\"Skipped,\", imagename, '. This file is either not .czi or .svs, or not the file assigned')\n",
    "    \n",
    "    try: \n",
    "        del vips_img \n",
    "        gc.collect()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print(\"processed in \", time.time()-start,\" seconds\")\n",
    "    print(\"____________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26675b34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to change names to add coordinates\n",
      "Processing NAID:  NA-5029-16_HE\n",
      "Processing NAID:  NA-5029-17_HE\n",
      "Processing NAID:  NA-5029-18_HE\n",
      "Processing NAID:  NA5004-16_HE\n",
      "Processing NAID:  NA5004-17_HE\n",
      "Processing NAID:  NA5004-18_HE\n",
      "Processing NAID:  NA5007-16_HE\n",
      "Processing NAID:  NA5007-17_HE\n",
      "Processing NAID:  NA5007-18_HE\n",
      "Processing NAID:  NA5009-16_HE\n",
      "Processing NAID:  NA5009-17_HE\n",
      "Processing NAID:  NA5009-18_HE\n",
      "Processing NAID:  NA5031-16_HE\n",
      "Processing NAID:  NA5031-17_HE\n",
      "Processing NAID:  NA5031-18_HE\n",
      "Processing NAID:  NA5041-16_HE\n",
      "Processing NAID:  NA5041-17_HE\n",
      "Processing NAID:  NA5041-18_HE\n",
      "Processing NAID:  NA5045-16_HE\n",
      "Processing NAID:  NA5045-17_HE\n",
      "Processing NAID:  NA5045-18_HE\n",
      "Processing NAID:  NA5051-16_HE\n",
      "Processing NAID:  NA5051-17_HE\n",
      "Processing NAID:  NA5051-18_HE\n",
      "Processing NAID:  NA5057-16_HE\n",
      "Processing NAID:  NA5057-17_HE\n",
      "Processing NAID:  NA5057-18_HE\n",
      "Processing NAID:  NA5063-16_HE\n",
      "Processing NAID:  NA5063-17_HE\n",
      "Processing NAID:  NA5063-18_HE\n",
      "Processing NAID:  NA5077-16_HE\n",
      "Processing NAID:  NA5077-17_HE\n",
      "Processing NAID:  NA5077-18_HE\n",
      "Processing NAID:  NA5085-16_HE\n",
      "Processing NAID:  NA5085-17_HE\n",
      "Processing NAID:  NA5085-18_HE\n",
      "Processing NAID:  NA5089-16_HE\n",
      "Processing NAID:  NA5089-17_HE\n",
      "Processing NAID:  NA5089-18_HE\n",
      "Processing NAID:  NA5090-16_HE\n",
      "Processing NAID:  NA5090-17_HE\n",
      "Processing NAID:  NA5090-18_HE\n",
      "Processing NAID:  NA5091-16_HE\n",
      "Processing NAID:  NA5091-17_HE\n",
      "Processing NAID:  NA5091-18_HE\n",
      "Processing NAID:  NA5093-16_HE\n",
      "Processing NAID:  NA5093-17_HE\n",
      "Processing NAID:  NA5093-18_HE\n",
      "Processing NAID:  NA5095-16_HE\n",
      "Processing NAID:  NA5095-17_HE\n",
      "Processing NAID:  NA5095-18_HE\n",
      "Processing NAID:  NA5098-16_HE\n",
      "Processing NAID:  NA5098-17_HE\n",
      "Processing NAID:  NA5098-18_HE\n",
      "Processing NAID:  NA5114-16_HE\n",
      "Processing NAID:  NA5114-17_HE\n",
      "Processing NAID:  NA5114-18_HE\n",
      "Processing NAID:  NA5116-16_HE\n",
      "Processing NAID:  NA5116-17_HE\n",
      "Processing NAID:  NA5116-18_HE\n",
      "Processing NAID:  NA5137-16_HE\n",
      "Processing NAID:  NA5137-17_HE\n",
      "Processing NAID:  NA5137-18_HE\n",
      "Processing NAID:  NA5146-16_HE\n",
      "Processing NAID:  NA5146-17_HE\n",
      "Processing NAID:  NA5146-18_HE\n",
      "Processing NAID:  NA5161-16_HE\n",
      "Processing NAID:  NA5161-17_HE\n",
      "Processing NAID:  NA5161-18_HE\n"
     ]
    }
   ],
   "source": [
    "###### SEGMENTATION - Give tile name based on coordinate\n",
    "\n",
    "print(\"About to change names to add coordinates\")\n",
    "for case_folder in sorted(os.listdir(SAVE_DIR)):\n",
    "    NAID = case_folder\n",
    "    print('Processing NAID: ', NAID)\n",
    "    for tile_folder in sorted(os.listdir(SAVE_DIR+NAID+'/0/')):\n",
    "        # folder_level == y axis distance determinant\n",
    "        # file_level == x axis distance determinant\n",
    "        y0 = int(tile_folder)*TILE_SIZE\n",
    "        y1 = (int(tile_folder)+1)*TILE_SIZE\n",
    "        #print(\"Y axis = (\", y0,',',y1,')')\n",
    "        for tile_file in sorted(os.listdir(SAVE_DIR+NAID+'/0/'+tile_folder+'/')):\n",
    "            x0 = int(tile_file.split('.')[0])*TILE_SIZE\n",
    "            x1 = (int(tile_file.split('.')[0])+1)*TILE_SIZE\n",
    "            #print(\"X axis = (\", x0,',',x1,')')\n",
    "            #print(\"Renaming \", SAVE_DIR+NAID+'/0/'+str(tile_folder)+'/'+tile_file)\n",
    "            os.rename(SAVE_DIR+NAID+'/0/'+str(tile_folder)+'/'+tile_file, \n",
    "                      SAVE_DIR+NAID+'/0/'+str(tile_folder)+'/'+str(y0)+'_'+str(x0)+'_'+str(y1)+'_'+str(x1)+'_'+tile_file)\n",
    "            #print(\"Renamed into \", SAVE_DIR+NAID+'/0/'+tile_folder+'/'+str(y0)+'_'+str(x0)+'_'+str(y1)+'_'+str(x1)+'_'+t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48f40863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 24/69 [00:00<00:00, 179.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed in  3.337860107421875e-06  seconds\n",
      "____________________________________________\n",
      "processed in  1.1920928955078125e-06  seconds\n",
      "____________________________________________\n",
      "processed in  7.152557373046875e-07  seconds\n",
      "____________________________________________\n",
      "processed in  4.76837158203125e-07  seconds\n",
      "____________________________________________\n",
      "processed in  4.76837158203125e-07  seconds\n",
      "____________________________________________\n",
      "processed in  1.1920928955078125e-06  seconds\n",
      "____________________________________________\n",
      "processed in  7.152557373046875e-07  seconds\n",
      "____________________________________________\n",
      "processed in  7.152557373046875e-07  seconds\n",
      "____________________________________________\n",
      "processed in  4.76837158203125e-07  seconds\n",
      "____________________________________________\n",
      "processed in  1.430511474609375e-06  seconds\n",
      "____________________________________________\n",
      "processed in  7.152557373046875e-07  seconds\n",
      "____________________________________________\n",
      "processed in  4.76837158203125e-07  seconds\n",
      "____________________________________________\n",
      "processed in  4.76837158203125e-07  seconds\n",
      "____________________________________________\n",
      "processed in  7.152557373046875e-07  seconds\n",
      "____________________________________________\n",
      "processed in  4.76837158203125e-07  seconds\n",
      "____________________________________________\n",
      "processed in  4.76837158203125e-07  seconds\n",
      "____________________________________________\n",
      "processed in  7.152557373046875e-07  seconds\n",
      "____________________________________________\n",
      "processed in  4.76837158203125e-07  seconds\n",
      "____________________________________________\n",
      "processed in  9.5367431640625e-07  seconds\n",
      "____________________________________________\n",
      "processed in  4.76837158203125e-07  seconds\n",
      "____________________________________________\n",
      "processed in  7.152557373046875e-07  seconds\n",
      "____________________________________________\n",
      "Loading NA5051-16_HE.czi  ......\n",
      "processed in  0.05211448669433594  seconds\n",
      "____________________________________________\n",
      "Loading NA5051-17_HE.czi  ......\n",
      "processed in  0.03881025314331055  seconds\n",
      "____________________________________________\n",
      "Loading NA5051-18_HE.czi  ......\n",
      "processed in  0.035617828369140625  seconds\n",
      "____________________________________________\n",
      "processed in  3.337860107421875e-06  seconds\n",
      "____________________________________________\n",
      "processed in  1.1920928955078125e-06  seconds\n",
      "____________________________________________\n",
      "processed in  1.430511474609375e-06  seconds\n",
      "____________________________________________\n",
      "Loading NA5063-16_HE.czi  ......\n",
      "processed in  0.040337562561035156  seconds\n",
      "____________________________________________\n",
      "Loading NA5063-17_HE.czi  ......\n",
      "processed in  0.04021334648132324  seconds\n",
      "____________________________________________\n",
      "Loading NA5063-18_HE.czi  ......\n",
      "processed in  0.11511516571044922  seconds\n",
      "____________________________________________\n",
      "Loading NA5077-16_HE.czi  ......\n",
      "processed in  0.04239678382873535  seconds\n",
      "____________________________________________\n",
      "Loading NA5077-17_HE.czi  ......\n",
      "processed in  0.04166436195373535  seconds\n",
      "____________________________________________\n",
      "Loading NA5077-18_HE.czi  ......\n",
      "processed in  0.040723562240600586  seconds\n",
      "____________________________________________\n",
      "Loading NA5085-16_HE.czi  ......\n",
      "processed in  0.03786802291870117  seconds\n",
      "____________________________________________\n",
      "Loading NA5085-17_HE.czi  ......\n",
      "processed in  0.038641929626464844  seconds\n",
      "____________________________________________\n",
      "Loading NA5085-18_HE.czi  ......\n",
      "processed in  0.039066314697265625  seconds\n",
      "____________________________________________\n",
      "Loading NA5089-16_HE.czi  ......\n",
      "processed in  0.03782033920288086  seconds\n",
      "____________________________________________\n",
      "Loading NA5089-17_HE.czi  ......\n",
      "processed in  0.040015459060668945  seconds\n",
      "____________________________________________\n",
      "Loading NA5089-18_HE.czi  ......\n",
      "processed in  0.11568570137023926  seconds\n",
      "____________________________________________\n",
      "Loading NA5090-16_HE.czi  ......\n",
      "processed in  0.03856921195983887  seconds\n",
      "____________________________________________\n",
      "Loading NA5090-17_HE.czi  ......\n",
      "processed in  0.038546085357666016  seconds\n",
      "____________________________________________\n",
      "Loading NA5090-18_HE.czi  ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 42/69 [00:00<00:00, 40.97it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed in  0.037004709243774414  seconds\n",
      "____________________________________________\n",
      "Loading NA5091-16_HE.czi  ......\n",
      "processed in  0.040390729904174805  seconds\n",
      "____________________________________________\n",
      "Loading NA5091-17_HE.czi  ......\n",
      "processed in  0.04259204864501953  seconds\n",
      "____________________________________________\n",
      "Loading NA5091-18_HE.czi  ......\n",
      "processed in  0.04012298583984375  seconds\n",
      "____________________________________________\n",
      "Loading NA5093-16_HE.czi  ......\n",
      "processed in  0.0407557487487793  seconds\n",
      "____________________________________________\n",
      "Loading NA5093-17_HE.czi  ......\n",
      "processed in  0.043538808822631836  seconds\n",
      "____________________________________________\n",
      "Loading NA5093-18_HE.czi  ......\n",
      "processed in  0.11716198921203613  seconds\n",
      "____________________________________________\n",
      "Loading NA5095-16_HE.czi  ......\n",
      "processed in  0.04244589805603027  seconds\n",
      "____________________________________________\n",
      "Loading NA5095-17_HE.czi  ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 51/69 [00:01<00:00, 31.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed in  0.043639183044433594  seconds\n",
      "____________________________________________\n",
      "Loading NA5095-18_HE.czi  ......\n",
      "processed in  0.040601253509521484  seconds\n",
      "____________________________________________\n",
      "Loading NA5098-16_HE.czi  ......\n",
      "processed in  0.039995670318603516  seconds\n",
      "____________________________________________\n",
      "Loading NA5098-17_HE.czi  ......\n",
      "processed in  0.041178226470947266  seconds\n",
      "____________________________________________\n",
      "Loading NA5098-18_HE.czi  ......\n",
      "processed in  0.038741111755371094  seconds\n",
      "____________________________________________\n",
      "Loading NA5114-16_HE.czi  ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 57/69 [00:01<00:00, 27.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed in  0.04429054260253906  seconds\n",
      "____________________________________________\n",
      "Loading NA5114-17_HE.czi  ......\n",
      "processed in  0.1206672191619873  seconds\n",
      "____________________________________________\n",
      "Loading NA5114-18_HE.czi  ......\n",
      "processed in  0.04523038864135742  seconds\n",
      "____________________________________________\n",
      "Loading NA5116-16_HE.czi  ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 62/69 [00:01<00:00, 26.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed in  0.03956413269042969  seconds\n",
      "____________________________________________\n",
      "Loading NA5116-17_HE.czi  ......\n",
      "processed in  0.03751325607299805  seconds\n",
      "____________________________________________\n",
      "Loading NA5116-18_HE.czi  ......\n",
      "processed in  0.038360595703125  seconds\n",
      "____________________________________________\n",
      "Loading NA5137-16_HE.czi  ......\n",
      "processed in  0.038420915603637695  seconds\n",
      "____________________________________________\n",
      "Loading NA5137-17_HE.czi  ......\n",
      "processed in  0.039307355880737305  seconds\n",
      "____________________________________________\n",
      "Loading NA5137-18_HE.czi  ......\n",
      "processed in  0.03811335563659668  seconds\n",
      "____________________________________________\n",
      "processed in  3.5762786865234375e-06  seconds\n",
      "____________________________________________\n",
      "processed in  9.5367431640625e-07  seconds\n",
      "____________________________________________\n",
      "processed in  1.1920928955078125e-06  seconds\n",
      "____________________________________________\n",
      "Loading NA5161-16_HE.czi  ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:02<00:00, 32.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed in  0.03740048408508301  seconds\n",
      "____________________________________________\n",
      "Loading NA5161-17_HE.czi  ......\n",
      "processed in  0.11650562286376953  seconds\n",
      "____________________________________________\n",
      "Loading NA5161-18_HE.czi  ......\n",
      "processed in  0.03840994834899902  seconds\n",
      "____________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###### SEGMENTATION - Extract polygon annotation\n",
    "\n",
    "for imagename in tqdm(imagenames[:]):\n",
    "    start = time.time()\n",
    "    if imagename.split('.')[-1] == 'svs':\n",
    "        pass\n",
    "        \n",
    "    elif imagename.split('.')[-1] == 'czi':\n",
    "        NAID = imagename.split('.')[0]\n",
    "        print(\"Loading\", imagename, \" ......\")\n",
    "        try: \n",
    "            czifile = pylibczi.CziFile(WSI_DIR + imagename, metafile_out = CZ_DIR + NAID + '.cz',use_pylibczi=True, verbose=True)\n",
    "            czifile.read_meta()\n",
    "            \n",
    "            tree = ET.parse(CZ_DIR + NAID + '.cz') \n",
    "            root = tree.getroot() \n",
    "            \n",
    "            tree.write(CZ_DIR + NAID + '.xml')\n",
    "        except:\n",
    "            print(\"Error in extracting annotation\")\n",
    "            \n",
    "    print(\"processed in \", time.time()-start,\" seconds\")\n",
    "    print(\"____________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "707c4aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_svs_annot(path):\n",
    "    doc = xmltodict.parse(open(path, 'r', encoding='utf-8').read())\n",
    "    \n",
    "    all_annot = []\n",
    "    if type(doc['Annotations']['Annotation']['Regions']['Region']) == list:\n",
    "        for region_idx in range(len(doc['Annotations']['Annotation']['Regions']['Region'])):\n",
    "            coords = []\n",
    "            for annot in doc['Annotations']['Annotation']['Regions']['Region'][region_idx]['Vertices']['Vertex']:\n",
    "                coord = [int(annot['@Y']),int(annot['@X'])]\n",
    "\n",
    "                coords.append(coord)\n",
    "            all_annot.append(coords)\n",
    "    else:\n",
    "        coords = []\n",
    "        for annot in doc['Annotations']['Annotation']['Regions']['Region']['Vertices']['Vertex']:\n",
    "            coord = [int(annot['@Y']),int(annot['@X'])]\n",
    "\n",
    "            coords.append(coord)\n",
    "        all_annot.append(coords)\n",
    "    \n",
    "    return all_annot\n",
    "\n",
    "#from: https://stackoverflow.com/questions/9807634/find-all-occurrences-of-a-key-in-nested-dictionaries-and-lists\n",
    "def findkeys(node, kv):\n",
    "    if isinstance(node, list):\n",
    "        for i in node:\n",
    "            for x in findkeys(i, kv):\n",
    "               yield x\n",
    "    elif isinstance(node, dict):\n",
    "        if kv in node:\n",
    "            yield node[kv]\n",
    "        for j in node.values():\n",
    "            for x in findkeys(j, kv):\n",
    "                yield x\n",
    "\n",
    "def grab_czi_annot(path):\n",
    "    doc = xmltodict.parse(open(path, 'r', encoding='utf-8').read())\n",
    "    \n",
    "    amt_annot = len(list(findkeys(doc,'Points')))\n",
    "    \n",
    "    all_annot = []\n",
    "    coords = []\n",
    "    \n",
    "    #print(\"AMOUNT ANNOT = \", amt_annot)\n",
    "    \n",
    "    for annot_idx in range(amt_annot):\n",
    "        coords = []\n",
    "        all_cord = list(findkeys(doc,'Points'))[annot_idx].split(' ')\n",
    "        isGood = False\n",
    "        for xy in all_cord:\n",
    "            #print(xy)\n",
    "            if int(float(xy.split(',')[1])) < 0 or int(float(xy.split(',')[0])) < 0:\n",
    "                pass\n",
    "                #print(\"Passed on negative coordinates\")\n",
    "            else:\n",
    "                coord = [int(float(xy.split(',')[1])),int(float(xy.split(',')[0]))]\n",
    "                isGood = True\n",
    "                \n",
    "                coords.append(coord)\n",
    "        if isGood:\n",
    "            all_annot.append(coords)\n",
    "    \n",
    "    return all_annot\n",
    "\n",
    "\n",
    "\n",
    "def create_polygon_mask(vertex_coordinates, mask):\n",
    "    \n",
    "    rr, cc = polygon(vertex_coordinates[:,0],vertex_coordinates[:,1],mask.shape)\n",
    "    mask[rr,cc] = 1\n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/41925853/fill-shapes-contours-using-numpy\n",
    "def fill_contours(arr):\n",
    "    return np.maximum.accumulate(arr,1) & \\\n",
    "           np.maximum.accumulate(arr[:,::-1],1)[:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd7a81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/69 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped, NA-5029-16_HE.svs . This file is either not .czi or .svs, or not the file assigned\n",
      "Skipped, NA-5029-17_HE.svs . This file is either not .czi or .svs, or not the file assigned\n",
      "Loading NA-5029-18_HE.svs  ......\n",
      "Loaded Image: /cache/Inf_May23_dataset/NA-5029-18_HE.svs\n",
      "Resizing small case\n",
      "Filling contours\n",
      "Saving mask contours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3/69 [00:51<18:46, 17.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed in  51.098061084747314  seconds\n",
      "____________________________________________\n",
      "Skipped, NA5004-16_HE.svs . This file is either not .czi or .svs, or not the file assigned\n",
      "Skipped, NA5004-17_HE.svs . This file is either not .czi or .svs, or not the file assigned\n",
      "Loading NA5004-18_HE.svs  ......\n",
      "Loaded Image: /cache/Inf_May23_dataset/NA5004-18_HE.svs\n",
      "Resizing small case\n",
      "Filling contours\n",
      "Saving mask contours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 6/69 [01:20<13:24, 12.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed in  29.226657390594482  seconds\n",
      "____________________________________________\n",
      "Skipped, NA5007-16_HE.svs . This file is either not .czi or .svs, or not the file assigned\n",
      "Skipped, NA5007-17_HE.svs . This file is either not .czi or .svs, or not the file assigned\n",
      "Skipped, NA5007-18_HE.svs . This file is either not .czi or .svs, or not the file assigned\n",
      "Skipped, NA5009-16_HE.svs . This file is either not .czi or .svs, or not the file assigned\n",
      "Skipped, NA5009-17_HE.svs . This file is either not .czi or .svs, or not the file assigned\n",
      "Loading NA5009-18_HE.svs  ......\n",
      "Loaded Image: /cache/Inf_May23_dataset/NA5009-18_HE.svs\n",
      "Filling contours\n"
     ]
    }
   ],
   "source": [
    "###### SEGMENTATION - Generate Masks based on Polygon Annotation\n",
    "\n",
    "gt_df = pd.read_csv('/cache/S23_Infarct/gt.csv')\n",
    "\n",
    "for imagename in tqdm(imagenames[:]):\n",
    "    start = time.time()\n",
    "\n",
    "    wsi_gt = gt_df[gt_df.cases == imagename].iat[0,2]\n",
    "    \n",
    "    resized = False\n",
    "    if wsi_gt == 1:\n",
    "        if imagename.split('.')[-1] == 'svs':\n",
    "            NAID = imagename.split('.')[0]\n",
    "            print(\"Loading\", imagename, \" ......\")\n",
    "            if True: \n",
    "                vips_img = Vips.Image.new_from_file(WSI_DIR + imagename, level=0)\n",
    "                print(\"Loaded Image: \" + WSI_DIR + imagename)\n",
    "                \n",
    "                if NAID in ['NA5009-16_HE', 'NA5009-17_HE', 'NA5009-18_HE']:\n",
    "                    pass\n",
    "                    #vips_img = vips_img.resize(0.25)\n",
    "                else:\n",
    "                    print(\"Resizing small case\")\n",
    "                    vips_img = vips_img.resize(2)\n",
    "                    resized = True\n",
    "\n",
    "                dimension = [vips_img.height, vips_img.width]\n",
    "\n",
    "                all_annot = grab_svs_annot(CZ_DIR + NAID + '.xml')\n",
    "\n",
    "                mask = np.zeros(dimension,'uint8')\n",
    "                \n",
    "                # It is all matching xml up to here\n",
    "                #print(all_annot)\n",
    "                \n",
    "                for coords in all_annot:\n",
    "                    #Old method - faulty\n",
    "                    #mask = create_polygon_mask(coords, mask)\n",
    "                    \n",
    "                    #New method - faulty\n",
    "                    for coord in coords:\n",
    "                        y = coord[0]\n",
    "                        x = coord[1]\n",
    "                        \n",
    "                        #print(\"y = \", y, \"x = \", x)\n",
    "                        if resized:\n",
    "                            y = y*2\n",
    "                            x = x*2\n",
    "                            mask[y][x] = 1\n",
    "                        else:\n",
    "                            mask[y][x] = 1\n",
    "                \n",
    "                print(\"Filling contours\")\n",
    "                mask = fill_contours(mask)\n",
    "\n",
    "                #mask = np.packbits(mask,axis=None)\n",
    "                #print(\"Binarized mask\")\n",
    "                \n",
    "                print(\"Saving mask contours\")\n",
    "                np.save(MASK_DIR+NAID+'.npy',mask)\n",
    "\n",
    "                print(\"processed in \", time.time()-start,\" seconds\")\n",
    "                print(\"____________________________________________\")\n",
    "\n",
    "            else:\n",
    "                print(\"Error in generating masks from polygon for \", NAID)\n",
    "\n",
    "\n",
    "        elif imagename.split('.')[-1] == 'czi':\n",
    "            ### TO DO: CHECK IF GENERALIZABLE TO ALL CASES, INCLUDING WITH SINGLE OR MULTIPLE TRACES\n",
    "\n",
    "            NAID = imagename.split('.')[0]\n",
    "            print(\"Loading\", imagename, \" ......\")\n",
    "            if True: \n",
    "                vips_img = grabCZI(WSI_DIR + imagename)\n",
    "                print(\"Loaded Image: \" + WSI_DIR + imagename)\n",
    "\n",
    "                dimension = [vips_img.height, vips_img.width]\n",
    "                all_annot = grab_czi_annot(CZ_DIR + NAID + '.xml')\n",
    "\n",
    "                mask = np.zeros(dimension,'uint8')\n",
    "                \n",
    "                # It is all matching up to here\n",
    "                #print(all_annot)\n",
    "                \n",
    "                for coords in all_annot:\n",
    "                    #Old method - faulty\n",
    "                    #mask = create_polygon_mask(coords, mask)\n",
    "                    \n",
    "                    #New method - faulty\n",
    "                    for coord in coords:\n",
    "                        y = coord[0]\n",
    "                        x = coord[1]\n",
    "                        \n",
    "                        #print(\"y = \", y, \"x = \", x)\n",
    "                        \n",
    "                        mask[y][x] = 1\n",
    "                        \n",
    "                print(\"Filling contours\")\n",
    "                mask = fill_contours(mask)\n",
    "\n",
    "                #mask = np.packbits(mask,axis=None)\n",
    "                #print(\"Binarized mask\")\n",
    "                \n",
    "                print(\"Saving mask contours\")\n",
    "                np.save(MASK_DIR+NAID+'.npy',mask) \n",
    "\n",
    "                print(\"processed in \", time.time()-start,\" seconds\")\n",
    "                print(\"____________________________________________\")\n",
    "            else:\n",
    "                print(\"Error in generating masks from polygon for \", NAID)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        print(\"Skipped,\", imagename, '. This file is either not .czi or .svs, or not the file assigned')\n",
    "    \n",
    "    if wsi_gt == 1:\n",
    "        del vips_img,coords,mask\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814175dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### SEGMENTATION - Find BG using ../saved_models/patched_512_NewAnnotation+preprocess_ResNet18_Feb12.pt (in 224)\n",
    "\n",
    "MODEL_SEG_DIR = './patched_512_NewAnnotation+preprocess_ResNet18_Feb12.pt'\n",
    "\n",
    "seg_model = torchvision.models.resnet18()\n",
    "seg_model.fc = nn.Linear(512, 3)\n",
    "\n",
    "checkpoint = torch.load(MODEL_SEG_DIR)\n",
    "seg_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "seg_model.to(device)\n",
    "\n",
    "\n",
    "for NAID in os.listdir(SAVE_DIR):\n",
    "    os.makedirs(SEGMENTATION_TILE_DIR+NAID+'/BG/')\n",
    "    for tile_folder in os.listdir(SAVE_DIR+NAID+'/0/'):\n",
    "        for tile in os.listdir(SAVE_DIR+NAID+'/0/'+tile_folder):\n",
    "            seg_model.train(False)\n",
    "            \n",
    "            img = Image.open(SAVE_DIR+NAID+'/0/'+tile_folder+'/'+tile)\n",
    "            \n",
    "            img_tensor = transforms.ToTensor()(img)\n",
    "            img_tensor = transforms.Normalize(mean=[0.4409763317567454, 0.4016568471536302, 0.4988298669112181],\n",
    "                             std=[0.31297803931100737, 0.2990562933047881, 0.33747493782548915])(img_tensor)\n",
    "            img_tensor = torch.reshape(img_tensor,(1,3,512,512))\n",
    "            img_tensor = img_tensor.cuda()\n",
    "            \n",
    "            predict = seg_model(img_tensor)\n",
    "            preds = F.sigmoid(predict)\n",
    "            _, indices = torch.max(predict.data, 1) # indices = 0:Background, 1:WM, 2:GM\n",
    "            indices = indices.type(torch.uint8)\n",
    "            running_seg =  indices.data.cpu()\n",
    "            \n",
    "            \n",
    "            if running_seg == 0:\n",
    "                shutil.copyfile(SAVE_DIR+NAID+'/0/'+tile_folder+'/'+tile, SEGMENTATION_TILE_DIR+NAID+'/BG/'+tile)\n",
    "            else:\n",
    "                pass\n",
    "                #print(\"bg removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7c162f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### SEGMENTATION - Separate tiles into BG, Inf and Healthy folders\n",
    "\n",
    "for NAID in os.listdir(SAVE_DIR):\n",
    "    proceed = True\n",
    "    \n",
    "    if os.path.isfile(WSI_DIR+NAID+'.svs'):\n",
    "        vips_img = Vips.Image.new_from_file(WSI_DIR+NAID+'.svs', level=0)\n",
    "        \n",
    "        if NAID in ['NA5009-16_HE', 'NA5009-17_HE', 'NA5009-18_HE']:\n",
    "            pass\n",
    "            #vips_img = vips_img.resize(0.25)\n",
    "        else:\n",
    "            print(\"Resizing small case\")\n",
    "            vips_img = vips_img.resize(2)\n",
    "            \n",
    "    elif os.path.isfile(WSI_DIR+NAID+'.czi'):\n",
    "        vips_img = grabCZI(WSI_DIR+NAID+'.czi')\n",
    "    else:\n",
    "        print(\"Could not find WSI - it is not czi nor svs\")\n",
    "        proceed = False\n",
    "    \n",
    "    if proceed:\n",
    "        os.makedirs(SEGMENTATION_TILE_DIR+NAID+'/Heal/')\n",
    "        os.makedirs(SEGMENTATION_TILE_DIR+NAID+'/Inf/')\n",
    "        \n",
    "        img_dim = [vips_img.height,vips_img.width]\n",
    "        mask = np.load(MASK_DIR+NAID+'.npy')\n",
    "        print(\"Loaded mask at \", MASK_DIR+NAID+'.npy' ,\", about to process...\")\n",
    "\n",
    "        im_size = img_dim[0]*img_dim[1]\n",
    "\n",
    "        #mask = np.unpackbits(mask,count=im_size).reshape(img_dim).view(bool)\n",
    "        #mask = mask.view(np.uint8)\n",
    "        print(\"Unbinarized mask\")\n",
    "        \n",
    "        \n",
    "        for tile_folder in os.listdir(SAVE_DIR+NAID+'/0/'):\n",
    "            for tile in os.listdir(SAVE_DIR+NAID+'/0/'+tile_folder):\n",
    "\n",
    "                #file naming convention --> y0 x0 y1 x1\n",
    "                y0 = tile.split('_')[0]\n",
    "                x0 = tile.split('_')[1]\n",
    "                y1 = tile.split('_')[2]\n",
    "                x1 = tile.split('_')[3]\n",
    "                \n",
    "                if sum(sum(masky[y0:y1,x0:x1])) >= (512/3):\n",
    "                    shutil.copyfile(SAVE_DIR+NAID+'/0/'+tile_folder+'/'+tile, SEGMENTATION_TILE_DIR+NAID+'/Inf/'+tile)\n",
    "                else:\n",
    "                    shutil.copyfile(SAVE_DIR+NAID+'/0/'+tile_folder+'/'+tile, SEGMENTATION_TILE_DIR+NAID+'/Heal/'+tile)\n",
    "            \n",
    "            \n",
    "    del vips_img, mask\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
